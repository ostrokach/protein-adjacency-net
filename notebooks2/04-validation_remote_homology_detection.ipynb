{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import itertools\n",
    "import importlib\n",
    "import multiprocessing\n",
    "import os\n",
    "import os.path as op\n",
    "import pickle\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import seaborn as sns\n",
    "import sqlalchemy as sa\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "\n",
    "from kmtools import py_tools, sequence_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PATH = Path.cwd().joinpath('..', 'src').resolve(strict=True)\n",
    "\n",
    "if SRC_PATH.as_posix() not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH.as_posix())\n",
    "\n",
    "import helper\n",
    "importlib.reload(helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_PATH = Path('validation_remote_homology_detection')\n",
    "NOTEBOOK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = Path(os.getenv('OUTPUT_DIR', NOTEBOOK_PATH.name)).resolve()\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = subprocess.run([\"git\", \"rev-parse\", \"--short\", \"HEAD\"], stdout=subprocess.PIPE)\n",
    "GIT_REV = proc.stdout.decode().strip()\n",
    "GIT_REV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_ID = os.getenv(\"SLURM_ARRAY_TASK_ID\")\n",
    "TASK_COUNT = os.getenv(\"ORIGINAL_ARRAY_TASK_COUNT\") or os.getenv(\"SLURM_ARRAY_TASK_COUNT\")\n",
    "NETWORK_NAME = os.getenv(\"CI_COMMIT_SHA\")\n",
    "\n",
    "TASK_ID = int(TASK_ID) if TASK_ID is not None else None\n",
    "TASK_COUNT = int(TASK_COUNT) if TASK_COUNT is not None else None\n",
    "\n",
    "TASK_ID, TASK_COUNT, NETWORK_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = \"CI\" not in os.environ    \n",
    "DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    NETWORK_NAME = \"dcn_old_0,6bbf5b792c30570b8ab1a4c1b3426cdc6ad84446\"\n",
    "else:\n",
    "    assert NETWORK_NAME is not None\n",
    "    \n",
    "NETWORK_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if DEBUG:\n",
    "#     %load_ext autoreload\n",
    "#     %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DATAPKG`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPKG = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPKG['uniparc-domain-wstructure'] = (\n",
    "    Path(os.environ['DATAPKG_OUTPUT_DIR'])\n",
    "    .joinpath(\"uniparc-domain-wstructure\", \"master\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPKG['adjacency_net_v2'] = (\n",
    "    Path(os.environ['DATAPKG_OUTPUT_DIR'])\n",
    "    .joinpath(\"adjacency-net-v2\", \"master\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPKG['hhsuite-wstructure'] = (\n",
    "    Path(os.environ['DATAPKG_OUTPUT_DIR'])\n",
    "    .joinpath(\"hhsuite-wstructure\", \"master\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote homology detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_homology_dataset_file = (\n",
    "    DATAPKG['hhsuite-wstructure']\n",
    "    .joinpath('scop_remote_homology_detection', 'remote_homology_dataset.parquet')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_homology_dataset = pq.read_table(remote_homology_dataset_file).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(remote_homology_dataset.head(2))\n",
    "print(len(remote_homology_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_homology_dataset['adjacency_coverage_1'] = (\n",
    "    remote_homology_dataset['adjacency_idx_1'].apply(lambda l: len(set(l))) /\n",
    "    remote_homology_dataset['sequence'].str.len()\n",
    ")\n",
    "\n",
    "\n",
    "remote_homology_dataset['adjacency_coverage_2'] = (\n",
    "    remote_homology_dataset['adjacency_idx_2'].apply(lambda l: len(set(l))) /\n",
    "    remote_homology_dataset['sequence'].str.len()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def validate_adjacency_df(adjacency_df):\n",
    "    assert (adjacency_df['adjacency_idx_1'].apply(min) >= 0).all()\n",
    "    assert (adjacency_df['adjacency_idx_2'].apply(min) >= 0).all()\n",
    "    \n",
    "    assert (\n",
    "        adjacency_df['adjacency_idx_1'].apply(max) <\n",
    "        adjacency_df['sequence'].str.len()\n",
    "    ).all()\n",
    "\n",
    "    assert (\n",
    "        adjacency_df['adjacency_idx_2'].apply(max) <\n",
    "        adjacency_df['sequence'].str.len()\n",
    "    ).all()\n",
    "\n",
    "    \n",
    "validate_adjacency_df(remote_homology_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run trained_networks.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network_name in NETWORK_NAME.split(','):\n",
    "    remote_homology_dataset[network_name] = (\n",
    "        helper.predict_with_network(\n",
    "            remote_homology_dataset.copy(),\n",
    "            network_state=TRAINED_NETWORKS[network_name]['network_state'],\n",
    "            network_info=TRAINED_NETWORKS[network_name]['network_info'],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not remote_homology_dataset[NETWORK_NAME.split(',')].isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(remote_homology_dataset, preserve_index=True)\n",
    "pq.write_table(\n",
    "    table,\n",
    "    OUTPUT_PATH.joinpath(f\"{NETWORK_NAME}_dataset.parquet\"),\n",
    "    version='2.0',\n",
    "    flavor='spark',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `remote_homology_dataset_filtered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_homology_dataset['adjacency_coverage_1'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_homology_dataset['adjacency_coverage_2'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids_w3plus = {\n",
    "    query_id\n",
    "    for query_id, group in \n",
    "        remote_homology_dataset\n",
    "        .groupby('query_id')\n",
    "    if len(group) >= 3\n",
    "}\n",
    "\n",
    "remote_homology_dataset_filtered = (\n",
    "    remote_homology_dataset[\n",
    "        remote_homology_dataset['query_id'].isin(query_ids_w3plus)\n",
    "    ]\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "print(len(remote_homology_dataset))\n",
    "print(len(remote_homology_dataset_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = (\n",
    "    [\n",
    "        \"identity_calc\",\n",
    "        \"coverage_calc\", \n",
    "        \"identity\", \"similarity\",\n",
    "        \"score\",  \"probability\", # \"evalue\",\n",
    "        \"sum_probs\",\n",
    "    ] + NETWORK_NAME.split(',')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scop_level in [1, 2, 3, 4]:\n",
    "    remote_homology_dataset_filtered[f'scop_domain_matches_l{scop_level}'] = (\n",
    "        remote_homology_dataset_filtered.apply(\n",
    "            lambda row: \n",
    "                '.'.join(row['scop_domain'].split('.')[:scop_level]) == \n",
    "                '.'.join(row['scop_domain_canonical'].split('.')[:scop_level]),\n",
    "            axis=1,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DATA_ALL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ALL = {}\n",
    "for scop_level in [1, 2, 3, 4]:\n",
    "    df = remote_homology_dataset_filtered.copy()\n",
    "    data = []\n",
    "    for feature in features:\n",
    "        corr, pvalue = stats.spearmanr(df[feature], df[f'scop_domain_matches_l{scop_level}'])\n",
    "        auc = metrics.roc_auc_score(df[f'scop_domain_matches_l{scop_level}'], df[feature])\n",
    "        data.append((feature, corr, pvalue, auc))\n",
    "    out_df = pd.DataFrame(data, columns=['feature', 'correlation', 'pvalue', 'auc'])\n",
    "    DATA_ALL[scop_level] = len(df['query_id'].drop_duplicates()), len(df), out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `DATA_GBQ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DATA_GBQ = {}\n",
    "\n",
    "num_skips_small = {1: 0, 2: 0, 3: 0, 4: 0}\n",
    "num_skips_eq = {1: 0, 2: 0, 3: 0, 4: 0}\n",
    "num_skips_neq = {1: 0, 2: 0, 3: 0, 4: 0}\n",
    "\n",
    "for scop_level in [1, 2, 3, 4]:\n",
    "    df = remote_homology_dataset_filtered.copy()\n",
    "    data = {f: {'corrs': [], 'pvalues': [], 'aucs': []} for f in features}\n",
    "    count_groups = 0\n",
    "    count_rows = 0\n",
    "    for query_id, group in df.groupby('query_id'):\n",
    "        if len(group) < 3:\n",
    "            num_skips_small[scop_level] += 1\n",
    "            continue\n",
    "        elif (group[f'scop_domain_matches_l{scop_level}'] == True).all():\n",
    "            num_skips_eq[scop_level] += 1\n",
    "            continue\n",
    "        elif (group[f'scop_domain_matches_l{scop_level}'] == False).all():\n",
    "            num_skips_neq[scop_level] += 1\n",
    "            continue\n",
    "        for feature in features:\n",
    "            if len(group[feature].drop_duplicates()) == 1:\n",
    "                print(f\"Skipping '{feature}'\")\n",
    "                continue\n",
    "            corr, pvalue = stats.spearmanr(group[feature], group[f'scop_domain_matches_l{scop_level}'])\n",
    "            auc = metrics.roc_auc_score(group[f'scop_domain_matches_l{scop_level}'], group[feature])\n",
    "            data[feature]['corrs'].append(corr)\n",
    "            data[feature]['pvalues'].append(pvalue)\n",
    "            data[feature]['aucs'].append(auc)\n",
    "        count_groups += 1\n",
    "        count_rows += len(group)\n",
    "    data_list = [\n",
    "        (k, np.mean(v['corrs']), np.mean(v['pvalues']), np.mean(v['aucs']))\n",
    "        for k, v in data.items()\n",
    "    ]\n",
    "    out_df = pd.DataFrame(data_list, columns=['feature', 'correlation', 'pvalue', 'auc'])\n",
    "    DATA_GBQ[scop_level] = count_groups, count_rows, out_df\n",
    "    \n",
    "print(num_skips_small)\n",
    "print(num_skips_eq)\n",
    "print(num_skips_neq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.get_cmap('Set1', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scop_levels = {\n",
    "    1: \"class\",\n",
    "    2: \"fold\",\n",
    "    3: \"superfamily\",\n",
    "    4: \"family\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = {\n",
    "    'identity_calc': 'identity (aln.)',\n",
    "    'coverage_calc': 'coverage (aln.)',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for scop_level in DATA_ALL:\n",
    "    fg, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    plt.sca(axs[0])\n",
    "    num1, num2, df = DATA_ALL[scop_level]\n",
    "    x = np.arange(len(df))\n",
    "    c = [cmap(2) if f in NETWORK_NAME.split(',') else cmap(1) for f in df['feature']]\n",
    "#     c = cmap(1)\n",
    "    plt.bar(x, df['auc'].abs(), color=c)\n",
    "    plt.xticks(x, [feature_names.get(f, f[:7]) for f in df['feature'].values], rotation=45)\n",
    "    plt.ylim(0.4, 1)\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.title(\n",
    "        f\"Predicting SCOP {scop_levels[scop_level]} - combined\\n\"\n",
    "        f\"(N = {num2}, M = {num1})\")\n",
    "    plt.hlines(0.5, -0.75, len(features) - 0.25, linestyle='--')\n",
    "    plt.ylim(0.4, 1)\n",
    "    plt.xlim(-0.75, len(features) - 0.25)\n",
    "\n",
    "    plt.sca(axs[1])\n",
    "    num1, num2, df = DATA_GBQ[scop_level]\n",
    "    x = np.arange(len(df))\n",
    "    c = [cmap(2) if f in NETWORK_NAME.split(',') else cmap(1) for f in df['feature']]\n",
    "#     c = cmap(1)\n",
    "    plt.bar(x, df['auc'].abs(), color=c)\n",
    "    plt.xticks(x, [feature_names.get(f, f[:7]) for f in df['feature'].values], rotation=45)\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.title(\n",
    "        f\"Predicting SCOP {scop_levels[scop_level]} - per protein\\n\"\n",
    "        f\"(N = {num2}, M = {num1})\")\n",
    "    plt.hlines(0.5, -0.75, len(features) - 0.25, linestyle='--')\n",
    "    plt.ylim(0.4, 1)\n",
    "    plt.xlim(-0.75, len(features) - 0.25)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_PATH.joinpath(f\"{NETWORK_NAME}_sl{scop_level}.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.savefig(OUTPUT_PATH.joinpath(f\"{NETWORK_NAME}_sl{scop_level}.pdf\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "418px",
    "left": "24px",
    "top": "169px",
    "width": "304px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
