{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Submitting jobs\n",
    "\n",
    "Note: These jobs must be submitted from the <code>./notebooks</code> folder.\n",
    "\n",
    "**Cedar**\n",
    "\n",
    "```bash\n",
    "NOTEBOOK_PATH=$(realpath 03_add_adjacency_distances.ipynb) ORIGINAL_ARRAY_TASK_COUNT=1027 sbatch --array=1,17,20,24,32,33,34,37,42,56,63,67,70,76,96,119,126,130,135,151,156,164,167,170,171,172,173,179,181,182,183,187,195,199,204,207,209,217,219,222,230,232,235,238,239,250,251,252,253,262,269,271,274,281,282,284,292,293,295,298,300,301,305,307,308,314,317,319,326,327,328,329,330,331,332,333,334,337,349,354,358,374,379,382,383,386,392,393,394,396,397,400,410,413,414,416,420,421,422,427,428,431,441,444,454,455,458,459,470,481,486,488,502,503,504,505,512,513,514,515,516,518,522,523,525,531,536,540,542,553,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,572,573,576,590,592,593,594,595,597,601,605,609,613,614,616,626,628,631,663,664,668,672,675,678,679,684,689,691,693,695,698,699,702,704,705,709,711,712,722,725,730,733,741,742,744,746,758,761,771,773,776,777,778,779,780,781,782,783,785,786,787,789,791,792,793,800,807,812,813,815,816,817,818,820,821,822,823,824,826,828,830,831,832,834,836,838,841,842,843,844,845,846,847,848,849,850,852,853,854,855,856,858,860,861,862,863,864,865,866,867,868,871,872,873,874,875,876,877,878,880,883,886,887,888,889,890,891,893,895,896,897,898,899,900,901,904,905,906,907,908,911,912,913,915,917,919,920,932,935,937,938,939,940,941,942,943,946,949,952,954,957,960,965,966,967,969,971,974,975,977,980,981,1011,1012 --time=72:00:00 --nodes=1 --tasks-per-node=48 --mem=0 --job-name=add-adjacency-distances --account=rrg-pmkim --output=/scratch/strokach/tmp/log/run-notebook-cpu-%j-%N.log ../scripts/run_notebook_cpu.sh\n",
    "```\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import concurrent.futures.process\n",
    "import importlib\n",
    "import logging\n",
    "import os\n",
    "import shlex\n",
    "import shutil\n",
    "import socket\n",
    "import subprocess\n",
    "import sys\n",
    "import traceback\n",
    "from functools import partial\n",
    "from itertools import islice\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import tenacity\n",
    "import yaml\n",
    "from kmbio import PDB\n",
    "from kmtools import structure_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PATH = Path.cwd().joinpath('..', 'src').resolve(strict=True)\n",
    "\n",
    "if SRC_PATH.as_posix() not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH.as_posix())\n",
    "\n",
    "import helper\n",
    "importlib.reload(helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_PATH = Path(os.getenv(\"CI_JOB_NAME\", \"03_add_adjacency_distances\"))\n",
    "NOTEBOOK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = Path(os.getenv('OUTPUT_DIR', NOTEBOOK_PATH.name)).resolve()\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.cwd().expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"scinet\" in socket.gethostname():\n",
    "    CPU_COUNT = 40\n",
    "else:\n",
    "    CPU_COUNT = max(1, len(os.sched_getaffinity(0)) // 2)\n",
    "\n",
    "CPU_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADJACENCY_MATRIX_PARQUET_PATH = Path(os.getenv(\"DATAPKG_OUTPUT_DIR\")).joinpath(\n",
    "    \"adjacency-net-v2\", \"v0.3\", \"training_dataset\", \"adjacency_matrix.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_ID = os.getenv(\"SLURM_ARRAY_TASK_ID\")\n",
    "TASK_COUNT = os.getenv(\"ORIGINAL_ARRAY_TASK_COUNT\") or os.getenv(\"SLURM_ARRAY_TASK_COUNT\")\n",
    "\n",
    "TASK_ID = int(TASK_ID) if TASK_ID is not None else None\n",
    "TASK_COUNT = int(TASK_COUNT) if TASK_COUNT is not None else None\n",
    "\n",
    "TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id_offset = os.getenv(\"TASK_ID_OFFSET\")\n",
    "if task_id_offset is not None:\n",
    "    TASK_ID += int(task_id_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = TASK_ID is None\n",
    "\n",
    "if DEBUG:\n",
    "    TASK_ID = 17\n",
    "    TASK_COUNT = 1027\n",
    "else:\n",
    "    assert TASK_ID is not None\n",
    "    assert TASK_COUNT is not None\n",
    "\n",
    "TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert len(os.listdir(ADJACENCY_MATRIX_PARQUET_PATH)) == TASK_COUNT, (\n",
    "#     len(os.listdir(ADJACENCY_MATRIX_PARQUET_PATH)),\n",
    "#     TASK_COUNT\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DATAPKG`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPKG = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPKG[\"pdb-ffindex\"] = {\n",
    "    \"pdb_mmcif_ffindex\": (\n",
    "        Path(os.environ[\"DATAPKG_OUTPUT_DIR\"]).joinpath(\"pdb-ffindex\", \"2018-09-06\", \"pdb-mmcif\")\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPKG[\"pdb-ffindex\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = sorted([d for d in ADJACENCY_MATRIX_PARQUET_PATH.glob(\"database_id=*\") if d.is_dir()])\n",
    "folders[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(folders[TASK_ID - 1].glob(\"*.parquet\"))\n",
    "\n",
    "print(files[:2])\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    pq.ParquetFile(files[0])\n",
    "    .read_row_group(0, use_pandas_metadata=True)\n",
    "    .to_pandas(integer_object_nulls=True)\n",
    "    .set_index(\"__index_level_0__\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on a single row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = list(islice(df.itertuples(), 3))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRUCTURE_URL_PREFIX = f\"ff://{DATAPKG['pdb-ffindex']['pdb_mmcif_ffindex']}?\"\n",
    "STRUCTURE_URL_PREFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = helper.get_adjacency_with_distances_and_orientations(\n",
    "#     row, max_cutoff=12, min_cutoff=None, structure_url_prefix=STRUCTURE_URL_PREFIX\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ar = results[\"distance\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fg, ax = plt.subplots()\n",
    "# ax.hist(ar.to_pylist(), range=(0, 12), bins=100)\n",
    "# None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test as part of a multiprocessing worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(data):\n",
    "    row = helper.to_namedtuple(data)\n",
    "\n",
    "    base = {}\n",
    "    for column in [\n",
    "        \"Index\",\n",
    "        \"uniparc_id\",\n",
    "        \"sequence\",\n",
    "        \"database\",\n",
    "        \"interpro_name\",\n",
    "        \"interpro_id\",\n",
    "        \"domain_start\",\n",
    "        \"domain_end\",\n",
    "        \"domain_length\",\n",
    "        \"structure_id\",\n",
    "        \"model_id\",\n",
    "        \"chain_id\",\n",
    "        \"pc_identity\",\n",
    "        \"alignment_length\",\n",
    "        \"mismatches\",\n",
    "        \"gap_opens\",\n",
    "        \"q_start\",\n",
    "        \"q_end\",\n",
    "        \"s_start\",\n",
    "        \"s_end\",\n",
    "        \"evalue_log10\",\n",
    "        \"bitscore\",\n",
    "        \"qseq\",\n",
    "        \"sseq\",\n",
    "    ]:\n",
    "        base[column] = [data[column]]\n",
    "    for column in [\"a2b\", \"b2a\", \"residue_id_1\", \"residue_id_2\", \"residue_aa_1\", \"residue_aa_2\"]:\n",
    "        if data[column].dtype in (int, float):\n",
    "            values = pa.array([(int(i) if pd.notnull(i) else None) for i in data[column]])\n",
    "        else:\n",
    "            values = pa.array(data[column].tolist())\n",
    "        base[column] = [values]\n",
    "\n",
    "    result = None\n",
    "    failure = None\n",
    "    try:\n",
    "        result = {\n",
    "            **tenacity.retry(\n",
    "                reraise=True,\n",
    "                retry=tenacity.retry_if_exception_type(StopIteration),\n",
    "                wait=tenacity.wait_random(min=0.5, max=2),\n",
    "                stop=tenacity.stop_after_attempt(5),\n",
    "            )(helper.get_adjacency_with_distances_and_orientations)(\n",
    "                row, max_cutoff=12, min_cutoff=None, structure_url_prefix=STRUCTURE_URL_PREFIX\n",
    "            ),\n",
    "            **base,\n",
    "        }\n",
    "        result = helper.downcast_and_compress(result)\n",
    "    except Exception as error:\n",
    "        exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "        traceback_string = \"\\n\".join(traceback.format_exception(exc_type, exc_value, exc_traceback))\n",
    "        failure = {\n",
    "            \"error_type\": [repr(type(error))],\n",
    "            \"error_message\": [str(error)],\n",
    "            \"error_traceback\": [traceback_string],\n",
    "            **base,\n",
    "        }\n",
    "        failure = helper.downcast_and_compress(failure)\n",
    "\n",
    "    return result, failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result, failure = worker(row._asdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = pa.RecordBatch.from_arrays(list(result.values()), list(result.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_file(file, failed=False):\n",
    "    file_parts = list(file.parts)\n",
    "    file_parts[-4] = file_parts[-4] + \"_wdistances\"\n",
    "    file_parts[-1] = file_parts[-1].split(\".\")[0] + \".arrow\"\n",
    "    if failed:\n",
    "        file_parts.insert(-3, \"failed\")\n",
    "    new_file = Path(*file_parts)\n",
    "    return new_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"kmtools.structure_tools.fixes\").setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_rows_processed = 0\n",
    "for file in tqdm(files):\n",
    "    ds = pq.ParquetFile(file)\n",
    "\n",
    "    new_file = get_new_file(file)\n",
    "    new_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    writer = None\n",
    "\n",
    "    new_file_failed = get_new_file(file, failed=True)\n",
    "    new_file_failed.parent.mkdir(parents=True, exist_ok=True)\n",
    "    writer_failed = None\n",
    "\n",
    "    for row_group in tqdm(range(ds.num_row_groups), leave=False):\n",
    "        df = (\n",
    "            ds.read_row_group(row_group, use_pandas_metadata=True)\n",
    "            .to_pandas(integer_object_nulls=True)\n",
    "            .set_index(\"__index_level_0__\")\n",
    "        )\n",
    "        num_rows_processed = 0\n",
    "        while num_rows_processed < len(df):\n",
    "            try:\n",
    "                with concurrent.futures.ProcessPoolExecutor(CPU_COUNT) as pool:\n",
    "                    futures = pool.map(\n",
    "                        worker, (t._asdict() for t in df.iloc[num_rows_processed:].itertuples()), chunksize=1\n",
    "                    )\n",
    "                    for result, failure in tqdm(futures, leave=False, total=len(df) - num_rows_processed):\n",
    "                        num_rows_processed += 1\n",
    "                        if result is None:\n",
    "                            assert failure is not None\n",
    "                        if result:\n",
    "                            batch = pa.RecordBatch.from_arrays(list(result.values()), list(result.keys()))\n",
    "                            if writer is None:\n",
    "                                writer = pa.RecordBatchFileWriter(new_file, batch.schema)\n",
    "                            writer.write_batch(batch)\n",
    "                        if failure:\n",
    "                            batch = pa.RecordBatch.from_arrays(list(failure.values()), list(failure.keys()))\n",
    "                            if writer_failed is None:\n",
    "                                writer_failed = pa.RecordBatchFileWriter(new_file_failed, batch.schema)\n",
    "                            writer_failed.write_batch(batch)\n",
    "            except concurrent.futures.process.BrokenProcessPool as e:\n",
    "                print(\n",
    "                    f\"ProcessPool crashed while processing row_group '{row_group}' in file '{file}'. \"\n",
    "                    f\"The error is '{type(e)}': '{e}'.\"\n",
    "                )\n",
    "        total_num_rows_processed += num_rows_processed\n",
    "    if writer is not None:\n",
    "        writer.close()\n",
    "    if writer_failed is not None:\n",
    "        writer_failed.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test that everything went ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    reader = pa.RecordBatchFileReader(new_file)\n",
    "except pa.ArrowIOError:\n",
    "    num_successful_batches = 0\n",
    "else:\n",
    "    num_successful_batches = reader.num_record_batches\n",
    "    \n",
    "num_successful_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    reader_failed = pa.RecordBatchFileReader(new_file_failed)\n",
    "except pa.ArrowIOError:\n",
    "    num_failed_batches = 0\n",
    "else:\n",
    "    num_failed_batches = reader_failed.num_record_batches\n",
    "    \n",
    "num_failed_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a `._SUCCESS` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with new_file.parent.joinpath(\"._SUCCESS\").open(\"wt\"):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "482px",
    "left": "34.9826px",
    "top": "126.979px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
