{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PATH = Path.cwd().joinpath('..', 'src').resolve(strict=True)\n",
    "\n",
    "if SRC_PATH.as_posix() not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH.as_posix())\n",
    "\n",
    "import helper\n",
    "importlib.reload(helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_PATH = Path(os.getenv(\"CI_JOB_NAME\", \"add_adjacency_distances_test\"))\n",
    "NOTEBOOK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = Path(os.getenv('OUTPUT_DIR', NOTEBOOK_PATH.name)).resolve()\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = \"CI\" not in os.environ    \n",
    "\n",
    "TASK_ID = os.getenv(\"SLURM_ARRAY_TASK_ID\")\n",
    "TASK_COUNT = os.getenv(\"ORIGINAL_ARRAY_TASK_COUNT\") or os.getenv(\"SLURM_ARRAY_TASK_COUNT\")\n",
    "\n",
    "TASK_ID = int(TASK_ID) if TASK_ID is not None else None\n",
    "TASK_COUNT = int(TASK_COUNT) if TASK_COUNT is not None else None\n",
    "\n",
    "TASK_ID, TASK_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DATAPKG`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPKG = {\n",
    "    'training_dataset': \n",
    "        Path(os.environ['DATAPKG_OUTPUT_DIR']).joinpath(\n",
    "            \"adjacency-net-v2\", \"master\", \"training_dataset\"),\n",
    "    'training_dataset_wdistances':\n",
    "        Path(os.environ['DATAPKG_OUTPUT_DIR']).joinpath(\n",
    "            \"adjacency-net-v2\", \"master\", \"training_dataset_wdistances\"),\n",
    "    'pdb_mmcif_ffindex':\n",
    "        Path(os.environ['DATAPKG_OUTPUT_DIR']).joinpath(\n",
    "            \"pdb-ffindex\", \"master\", \"pdb_mmcif_ffindex\", \"pdb-mmcif\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_files = list(\n",
    "    DATAPKG['training_dataset_wdistances'].joinpath(\"adjacency_matrix.parquet\").glob(\"*/*.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for i, parquet_file in enumerate(parquet_files[:10]):\n",
    "    print(i)\n",
    "    file_obj = pq.ParquetFile(parquet_file)\n",
    "    df = file_obj.read_row_group(0).to_pandas()\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = OUTPUT_PATH.joinpath(\"example_rows.parquet\")\n",
    "\n",
    "if not output_file.is_file():\n",
    "    table = pa.Table.from_pandas(master_df, preserve_index=False)\n",
    "    pq.write_table(table, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = OUTPUT_PATH.joinpath(\"example_rows.parquet\")\n",
    "\n",
    "master_df = pq.read_table(output_file).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = master_df[\n",
    "    (master_df['residue_idx_1_corrected'].notnull())\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_aa_distances`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aa_distances(seq, residue_idx_1_corrected, residue_idx_2_corrected):\n",
    "    arr1 = np.array(residue_idx_1_corrected)\n",
    "    arr2 = np.array(residue_idx_2_corrected)\n",
    "    aa_distances = np.hstack([np.zeros(len(seq), dtype=np.int), np.abs(arr1 - arr2)])\n",
    "    return aa_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df[\"aa_distances\"] = [\n",
    "    get_aa_distances(seq, idx1, idx2)\n",
    "    for seq, idx1, idx2\n",
    "    in master_df[[\"sequence\", \"residue_idx_1_corrected\", \"residue_idx_2_corrected\"]].values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df[\"aa_distances\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_distances = np.hstack(master_df[\"aa_distances\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `get_cart_distances`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cart_distances(seq, distances):\n",
    "    cart_distances = np.hstack([np.zeros(len(seq), dtype=np.float), distances])\n",
    "    return cart_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df[\"cart_distances\"] = [\n",
    "    get_cart_distances(seq, distances)\n",
    "    for seq, distances\n",
    "    in master_df[[\"sequence\", \"distances\"]].values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df[\"cart_distances\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_distances = np.hstack(master_df[\"cart_distances\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(aa_distances) == len(cart_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(aa_distances))\n",
    "np.random.RandomState(42).shuffle(indices)\n",
    "np.random.RandomState(42).shuffle(aa_distances)\n",
    "np.random.RandomState(42).shuffle(cart_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (cart_distances[:10_000][aa_distances[:10_000] == 0] == 0).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(OUTPUT_PATH.joinpath(\"aa_distances.npy\"), aa_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(OUTPUT_PATH.joinpath(\"cart_distances.npy\"), cart_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_distances = np.load(OUTPUT_PATH.joinpath(\"aa_distances.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_distances = np.load(OUTPUT_PATH.joinpath(\"cart_distances.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `gen_barcode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel=True)\n",
    "def gen_barcode(distances, bins):\n",
    "    barcode = np.zeros((len(distances), len(bins)), dtype=np.int32)\n",
    "    for i in prange(len(distances)):\n",
    "        a = distances[i]\n",
    "        for j in range(len(bins)):\n",
    "            if a < bins[j]:\n",
    "                barcode[i, j] = 1\n",
    "                break\n",
    "    return barcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize seq distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.clip(aa_distances, 0, 100), bins=50)\n",
    "plt.xlabel(\"Amino acid distance\")\n",
    "plt.label(\"Number of amino acid pairs\")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_seq_distances(aa_distances):\n",
    "    aa_distances_log_mean = 3.5567875815104903\n",
    "    aa_distances_log_std = 1.7065822763411669\n",
    "\n",
    "    with np.errstate(divide='ignore'):\n",
    "        aa_distances_log = np.where(aa_distances > 0, np.log(aa_distances) + 1, 0)\n",
    "        \n",
    "    aa_distances_corrected = (aa_distances_log - aa_distances_log_mean) / aa_distances_log_std\n",
    "    return aa_distances_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_distances_corrected = normalize_seq_distances(aa_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(aa_distances_corrected.mean(), 0)\n",
    "assert np.isclose(aa_distances_corrected.std(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(aa_distances_corrected, bins=50)\n",
    "plt.xlabel(\"Amino acid distance (normalized)\")\n",
    "plt.ylabel(\"Number of amino acid pairs\")\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bin seq distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_quantile_custom = normalize_seq_distances(np.array([1, 4, 8, 14, 32, 100_000])).tolist()\n",
    "aa_quantile_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_quantile_2 = np.quantile(aa_distances_corrected, np.linspace(0, 1, 3)[1:]).tolist()\n",
    "aa_quantile_4 = np.quantile(aa_distances_corrected, np.linspace(0, 1, 5)[1:]).tolist()\n",
    "aa_quantile_6 = np.quantile(aa_distances_corrected, np.linspace(0, 1, 7)[1:]).tolist()\n",
    "\n",
    "aa_quantile_2[-1] = aa_quantile_custom[-1]\n",
    "aa_quantile_4[-1] = aa_quantile_custom[-1]\n",
    "aa_quantile_6[-1] = aa_quantile_custom[-1]\n",
    "\n",
    "aa_quantile_2, aa_quantile_4, aa_quantile_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 3 gen_barcode(aa_distances_corrected, aa_quantile_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 3 gen_barcode(aa_distances_corrected, aa_quantile_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize cart distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.clip(cart_distances, 0, 14), bins=50)\n",
    "plt.xlabel(\"Euclidean distance\")\n",
    "plt.ylabel(\"Number of amino acid pairs\")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cart_distances(cart_distances):\n",
    "    cart_distances_mean = 6.9936892028873965\n",
    "    cart_distances_std = 3.528368101492991\n",
    "    \n",
    "    cart_distances_corrected = (cart_distances - cart_distances_mean) / cart_distances_std\n",
    "    return cart_distances_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_distances_corrected = normalize_cart_distances(cart_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(cart_distances_corrected.mean(), 0)\n",
    "assert np.isclose(cart_distances_corrected.std(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cart_distances_corrected, bins=50)\n",
    "plt.xlabel(\"Euclidean distance (normalized)\")\n",
    "plt.ylabel(\"Number of amino acid pairs\")\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bin cart distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_quantile_custom = normalize_cart_distances(np.array([1.0, 2.0, 4.0, 6.2, 8.5, 100_000.0])).tolist()\n",
    "cart_quantile_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_quantile_2 = np.quantile(cart_distances_corrected, np.linspace(0, 1, 3)[1:]).tolist()\n",
    "cart_quantile_4 = np.quantile(cart_distances_corrected, np.linspace(0, 1, 5)[1:]).tolist()\n",
    "cart_quantile_6 = np.quantile(cart_distances_corrected, np.linspace(0, 1, 7)[1:]).tolist()\n",
    "\n",
    "cart_quantile_2[-1] = cart_quantile_custom[-1]\n",
    "cart_quantile_4[-1] = cart_quantile_custom[-1]\n",
    "cart_quantile_6[-1] = cart_quantile_custom[-1]\n",
    "\n",
    "cart_quantile_2, cart_quantile_4, cart_quantile_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 3 gen_barcode(cart_distances, cart_quantile_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, barcode_size, hidden_layer_size=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.barcode_size = barcode_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.linear1 = nn.Linear(1, self.hidden_layer_size)\n",
    "        self.linear2 = nn.Linear(self.hidden_layer_size, self.barcode_size)\n",
    "        \n",
    "#         self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = np.sqrt(self.hidden_layer_size)\n",
    "        self.linear1.weight.data.normal_(0, stdv)\n",
    "        self.linear1.bias.data.normal_(0, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoDistanceNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, barcode_size, hidden_layer_size=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.barcode_size = barcode_size\n",
    "\n",
    "        self.linear1 = nn.Linear(2, self.hidden_layer_size)\n",
    "        self.linear2 = nn.Linear(self.hidden_layer_size, self.barcode_size)\n",
    "        \n",
    "#         self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = np.sqrt(self.hidden_layer_size)\n",
    "        self.linear1.weight.data.normal_(0, stdv)\n",
    "        self.linear1.bias.data.normal_(0, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(2 / 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_distances_onehot = gen_barcode(aa_distances_corrected, aa_quantile_custom).astype(np.float32)\n",
    "assert (aa_distances_onehot.sum(axis=1) == 1).all()\n",
    "\n",
    "cart_distances_onehot = gen_barcode(cart_distances_corrected, cart_quantile_custom).astype(np.float32)\n",
    "assert (cart_distances_onehot.sum(axis=1) == 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = DistanceNet(6)\n",
    "model_c = DistanceNet(6)\n",
    "model_ac = TwoDistanceNet(12)\n",
    "\n",
    "learning_rate = 1e-4  #0.00005\n",
    "betas = (0.5, 0.9)\n",
    "\n",
    "optimizer_a = torch.optim.Adam(model_a.parameters(), lr=learning_rate, betas=betas)\n",
    "optimizer_c = torch.optim.Adam(model_c.parameters(), lr=learning_rate, betas=betas)\n",
    "optimizer_ac = torch.optim.Adam(model_ac.parameters(), lr=learning_rate, betas=betas)\n",
    "\n",
    "# loss_fn = nn.BCELoss()\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "#\n",
    "losses_a = []\n",
    "losses_c = []\n",
    "losses_ac = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(30_000):\n",
    "    if t % 2_000 == 0:\n",
    "        print(t)\n",
    "    \n",
    "    t_slice = slice(t * batch_size, (t + 1) * batch_size)\n",
    "\n",
    "    X_a = torch.from_numpy(aa_distances_corrected[t_slice]).to(torch.float32).unsqueeze(1)\n",
    "    X_c = torch.from_numpy(cart_distances_corrected[t_slice]).to(torch.float32).unsqueeze(1)\n",
    "    X_ac = torch.cat([X_a, X_c], 1)\n",
    "\n",
    "    Y_a = torch.from_numpy(aa_distances_onehot[t_slice, :])\n",
    "    Y_c = torch.from_numpy(cart_distances_onehot[t_slice, :])\n",
    "    Y_ac = torch.cat([Y_a, Y_c], 1)\n",
    "\n",
    "    Y_a_pred = model_a(X_a)\n",
    "    Y_c_pred = model_c(X_c)\n",
    "    Y_ac_pred = model_ac(X_ac)\n",
    "\n",
    "    loss_a = loss_fn(Y_a_pred, Y_a)\n",
    "    losses_a.append(loss_a.detach().data.numpy())\n",
    "\n",
    "    loss_c = loss_fn(Y_c_pred, Y_c)\n",
    "    losses_c.append(loss_c.detach().data.numpy())\n",
    "\n",
    "    loss_ac = loss_fn(Y_ac_pred, Y_ac)\n",
    "    losses_ac.append(loss_ac.detach().data.numpy())\n",
    "\n",
    "    optimizer_a.zero_grad()\n",
    "    optimizer_c.zero_grad()\n",
    "    optimizer_ac.zero_grad()\n",
    "\n",
    "    loss_a.backward()\n",
    "    loss_c.backward()\n",
    "    loss_ac.backward()\n",
    "\n",
    "    optimizer_a.step()\n",
    "    optimizer_c.step()\n",
    "    optimizer_ac.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Sequence distance\n",
    "test_seq_distances = normalize_seq_distances(np.linspace(0, 50, 50)).astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "img = model_a(torch.from_numpy(test_seq_distances)).data.numpy()\n",
    "\n",
    "with plt.rc_context(rc={\"font.size\": 12}):\n",
    "    fig, ax = plt.subplots(figsize=(14, 2.5))\n",
    "    im = ax.imshow(img.T, aspect=2, extent=[-0.5, 50 - 0.5, 5 - 0.5, - 0.5])\n",
    "    fig.colorbar(im)\n",
    "    plt.xlabel(\"Sequence distance\")\n",
    "    plt.ylabel(\"One-hot encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Euclidean distance\n",
    "test_cart_distances = normalize_cart_distances(np.linspace(0, 12, 50)).astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "img = model_c(torch.from_numpy(test_cart_distances)).data.numpy()\n",
    "\n",
    "with plt.rc_context(rc={\"font.size\": 12}):\n",
    "    fig, ax = plt.subplots(figsize=(14, 2.5))\n",
    "    im = ax.imshow(img.T, aspect=12/50*2, extent=[-0.5, 12 - 0.5, 5 - 0.5, - 0.5])\n",
    "    fig.colorbar(im)\n",
    "    plt.xlabel(\"Euclidean distance\")\n",
    "    plt.ylabel(\"One-hot encoding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(13):\n",
    "    # Sequence - Euclidean distance\n",
    "    test_seq_cart_distances = np.hstack([\n",
    "        test_seq_distances,\n",
    "        np.ones((len(test_seq_distances), 1), dtype=np.float32) * normalize_cart_distances(i),\n",
    "    ])\n",
    "\n",
    "    img = model_ac(torch.from_numpy(test_seq_cart_distances)).data.numpy()\n",
    "\n",
    "    with plt.rc_context(rc={\"font.size\": 12}):\n",
    "        fig, ax = plt.subplots(figsize=(14, 5))\n",
    "        im = ax.imshow(img.T, aspect=12/50*8, extent=[-0.5, 50 - 0.5, 11 - 0.5, - 0.5])\n",
    "        fig.colorbar(im)\n",
    "        plt.xlabel(\"Euclidean distance\")\n",
    "        plt.ylabel(\"One-hot encoding\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    model_a.state_dict(),\n",
    "    \"/home/kimlab1/database_data/datapkg/adjacency-net-v2/src/model_data/seq_barcode_model.state\",\n",
    ")\n",
    "\n",
    "torch.save(\n",
    "    model_c.state_dict(),\n",
    "    \"/home/kimlab1/database_data/datapkg/adjacency-net-v2/src/model_data/cart_barcode_model.state\",\n",
    ")\n",
    "\n",
    "torch.save(\n",
    "    model_ac.state_dict(),\n",
    "    \"/home/kimlab1/database_data/datapkg/adjacency-net-v2/src/model_data/seq_cart_barcode_model.state\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `linear1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg, axs = plt.subplots(1, 2, figsize=(14, 4))\n",
    "axs[0].hist(model_a.linear1.weight.data.numpy().reshape(-1))\n",
    "axs[1].hist(model_a.linear1.bias.data.numpy().reshape(-1))\n",
    "\n",
    "print(model_a.linear1.weight.data.numpy().std())\n",
    "print(model_a.linear1.bias.data.numpy().std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg, axs = plt.subplots(1, 2, figsize=(14, 4))\n",
    "axs[0].hist(model_ac.linear1.weight.data.numpy().reshape(-1))\n",
    "axs[1].hist(model_ac.linear1.bias.data.numpy().reshape(-1))\n",
    "\n",
    "print(model_ac.linear1.weight.data.numpy().std())\n",
    "print(model_ac.linear1.bias.data.numpy().std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `linear2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg, axs = plt.subplots(1, 2, figsize=(14, 4))\n",
    "axs[0].hist(model_a.linear2.weight.data.numpy().reshape(-1))\n",
    "axs[1].hist(model_a.linear2.bias.data.numpy().reshape(-1))\n",
    "\n",
    "print(model_a.linear2.weight.data.numpy().std())\n",
    "print(model_a.linear2.bias.data.numpy().std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg, axs = plt.subplots(1, 2, figsize=(14, 4))\n",
    "axs[0].hist(model_ac.linear2.weight.data.numpy().reshape(-1))\n",
    "axs[1].hist(model_ac.linear2.bias.data.numpy().reshape(-1))\n",
    "\n",
    "print(model_ac.linear2.weight.data.numpy().std())\n",
    "print(model_ac.linear2.bias.data.numpy().std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_array = np.hstack(losses_ac)\n",
    "plt.plot(losses_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.eye(10, dtype=torch.float32).unsqueeze(0)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = nn.MaxPool1d(3, ceil_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.unsqueeze(0).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "482px",
    "left": "33.9688px",
    "top": "110px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
