{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Generate training and validation datasets.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run _imports.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run _settings.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run _spark.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import NamedTuple\n",
    "\n",
    "import h5py\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pagnn\n",
    "importlib.reload(pagnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "NOTEBOOK_NAME = 'mutation_datasets'\n",
    "NOTEBOOK_PATH = Path(NOTEBOOK_NAME).absolute()\n",
    "NOTEBOOK_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['DATABIN_DIR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene3D domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'generate_datasets/gene3d_domains.pickle', 'rb') as fin:\n",
    "    GENE3D_DOMAINS = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training / validation domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'generate_datasets/training_domains.pickle', 'rb') as fin:\n",
    "    TRAINING_DOMAINS = pickle.load(fin)\n",
    "    \n",
    "with open(f'generate_datasets/validation_domains.pickle', 'rb') as fin:\n",
    "    VALIDATION_DOMAINS = pickle.load(fin)\n",
    "    \n",
    "with open(f'generate_datasets/test_domains.pickle', 'rb') as fin:\n",
    "    TEST_DOMAINS = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training / validation parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'generate_datasets/training_parquet_files.pickle', 'rb') as fin:\n",
    "    TRAINING_PARQUET_FILES = pickle.load(fin)\n",
    "    \n",
    "with open(f'generate_datasets/validation_parquet_files.pickle', 'rb') as fin:\n",
    "    VALIDATION_PARQUET_FILES = pickle.load(fin)\n",
    "    \n",
    "with open(f'generate_datasets/test_parquet_files.pickle', 'rb') as fin:\n",
    "    TEST_PARQUET_FILES = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_DIR = NOTEBOOK_PATH.joinpath('validation')\n",
    "VALIDATION_DIR.mkdir(exist_ok=True)\n",
    "VALIDATION_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROTHERM_DIR = NOTEBOOK_PATH.joinpath('protherm')\n",
    "PROTHERM_DIR.mkdir(exist_ok=True)\n",
    "PROTHERM_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMSAVAR_DIR = NOTEBOOK_PATH.joinpath('humsavar')\n",
    "HUMSAVAR_DIR.mkdir(exist_ok=True)\n",
    "HUMSAVAR_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniparc xref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniparc_xref_file = op.join(os.environ['DATABIN_DIR'], 'uniparc', 'v0.1.0', 'uniparc_xref.parquet')\n",
    "uniparc_xref_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {uniparc_xref_file} -lSh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ds = spark.sql(f\"\"\"\\\n",
    "SELECT *\n",
    "FROM parquet.`{uniparc_xref_file}`\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 'UniProtKB/Swiss-Prot' | 'UniProtKB/TrEMBL'\n",
    "# active = 'Y'\n",
    "# db_id = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADJACENCY_MATRIX_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ds = spark.sql(f\"\"\"\\\n",
    "SELECT *\n",
    "FROM parquet.`{ADJACENCY_MATRIX_PATH}`\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protherm dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "protherm_file = (\n",
    "    op.join(os.environ['DATABIN_DIR'], 'protein_folding_energy', 'v0.1.0', 'protherm_star.parquet')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "protherm = pq.read_table(protherm_file).to_pandas().set_index('__index_level_0__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(protherm.head())\n",
    "print(protherm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "protherm = protherm.dropna(subset=['uniprot_id', 'uniprot_mutation', 'ddg_exp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protherm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADJACENCY_MATRIX_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "ds = spark.sql(f\"\"\"\\\n",
    "SELECT\n",
    "    ds.uniprot_id, ds.uniprot_mutation, ds.ddg_exp,\n",
    "    \n",
    "    xref.uniparc_id,\n",
    "    \n",
    "    ud.sequence, ud.database_id, ud.domain_start, ud.domain_end, ud.__index_level_0__ domain_index,\n",
    "       \n",
    "    ud.structure_id, ud.model_id, ud.chain_id,\n",
    "    ud.pc_identity, ud.alignment_length, ud.mismatches, ud.gap_opens, \n",
    "    ud.q_start, ud.q_end, ud.s_start, ud.s_end,\n",
    "    \n",
    "    ud.qseq, ud.sseq,\n",
    "    ud.residue_idx_1_corrected, ud.residue_idx_2_corrected\n",
    "\n",
    "FROM parquet.`{protherm_file}` ds\n",
    "JOIN parquet.`{uniparc_xref_file}` xref ON (uniprot_id = db_id)\n",
    "JOIN parquet.`{ADJACENCY_MATRIX_PATH}` ud USING (uniparc_id)\n",
    "WHERE (xref.db_type = 'UniProtKB/Swiss-Prot' OR xref.db_type = 'UniProtKB/TrEMBL')\n",
    "AND xref.active = 'Y'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ds.write.parquet(\n",
    "    PROTHERM_DIR.joinpath('protherm_2.parquet').as_posix(),\n",
    "    mode='overwrite',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove mutations outside domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protherm_df = pq.ParquetDataset(PROTHERM_DIR.joinpath('protherm_2.parquet').as_posix()).read().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(protherm_df.head(2))\n",
    "print(protherm_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pagnn.utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protherm_df = pagnn.filter_mismatch_mutations(protherm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protherm_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(protherm_df['ddg_exp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pq.write_table(\n",
    "    pa.Table.from_pandas(protherm_df, preserve_index=False),\n",
    "    NOTEBOOK_PATH.joinpath('protherm_validaton_dataset.parquet').as_posix(),\n",
    "    version='2.0',\n",
    "    flavor='spark',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROTHERM_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Humsavar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "humsavar_file = (\n",
    "    op.join(os.environ['DATABIN_DIR'], 'mutation_sets', 'v0.1.0', 'humsavar.parquet')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "humsavar = pq.read_table(humsavar_file).to_pandas().set_index('__index_level_0__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(humsavar.head())\n",
    "print(humsavar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "humsavar = humsavar.dropna(subset=['uniprot_id', 'uniprot_mutation', 'type_of_variant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humsavar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ds = spark.sql(f\"\"\"\\\n",
    "SELECT\n",
    "    ds.uniprot_id, ds.uniprot_mutation, ds.type_of_variant,\n",
    "    \n",
    "    xref.uniparc_id,\n",
    "    \n",
    "    ud.sequence, ud.database_id, ud.domain_start, ud.domain_end, ud.__index_level_0__ domain_index,\n",
    "       \n",
    "    ud.structure_id, ud.model_id, ud.chain_id,\n",
    "    ud.pc_identity, ud.alignment_length, ud.mismatches, ud.gap_opens, \n",
    "    ud.q_start, ud.q_end, ud.s_start, ud.s_end,\n",
    "    \n",
    "    ud.qseq, ud.sseq,\n",
    "    ud.residue_idx_1_corrected, ud.residue_idx_2_corrected\n",
    "\n",
    "FROM parquet.`{humsavar_file}` ds\n",
    "JOIN parquet.`{uniparc_xref_file}` xref ON (uniprot_id = db_id)\n",
    "JOIN parquet.`{ADJACENCY_MATRIX_PATH}` ud USING (uniparc_id)\n",
    "WHERE (xref.db_type = 'UniProtKB/Swiss-Prot' OR xref.db_type = 'UniProtKB/TrEMBL')\n",
    "AND xref.active = 'Y'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ds.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ds.write.parquet(\n",
    "    HUMSAVAR_DIR.joinpath('humsavar_2.parquet').as_posix(),\n",
    "    mode='overwrite',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove mutations outside domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humsavar_df = pq.ParquetDataset(HUMSAVAR_DIR.joinpath('humsavar_2.parquet').as_posix()).read().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(humsavar_df.head(2))\n",
    "print(humsavar_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pagnn.utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humsavar_df = pagnn.filter_mismatch_mutations(humsavar_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humsavar_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(humsavar_df['type_of_variant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "humsavar_df = humsavar_df[humsavar_df['type_of_variant'].isin({'Disease', 'Polymorphism'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(humsavar_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "humsavar_df['score_exp'] = (humsavar_df['type_of_variant'] == 'Disease').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pq.write_table(\n",
    "    pa.Table.from_pandas(humsavar_df, preserve_index=False),\n",
    "    NOTEBOOK_PATH.joinpath('humsavar_validaton_dataset.parquet').as_posix(),\n",
    "    version='2.0',\n",
    "    flavor='spark',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "602px",
    "left": "1640.28px",
    "right": "20px",
    "top": "106.354px",
    "width": "329px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
