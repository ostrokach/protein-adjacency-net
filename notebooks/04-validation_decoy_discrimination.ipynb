{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import itertools\n",
    "import importlib\n",
    "import multiprocessing\n",
    "import os\n",
    "import os.path as op\n",
    "import pickle\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import seaborn as sns\n",
    "import sqlalchemy as sa\n",
    "from scipy import stats\n",
    "\n",
    "from kmtools import py_tools, sequence_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 100)\n",
    "pd.set_option(\"max_rows\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PATH = Path.cwd().joinpath('..', 'src').resolve(strict=True)\n",
    "\n",
    "if SRC_PATH.as_posix() not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH.as_posix())\n",
    "    \n",
    "import helper\n",
    "importlib.reload(helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_PATH = Path('validation_decoy_discrimination')\n",
    "NOTEBOOK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = Path(os.getenv('OUTPUT_DIR', NOTEBOOK_PATH.name)).resolve()\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = subprocess.run([\"git\", \"rev-parse\", \"--short\", \"HEAD\"], stdout=subprocess.PIPE)\n",
    "GIT_REV = proc.stdout.decode().strip()\n",
    "GIT_REV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_ID = os.getenv(\"SLURM_ARRAY_TASK_ID\")\n",
    "TASK_COUNT = os.getenv(\"ORIGINAL_ARRAY_TASK_COUNT\") or os.getenv(\"SLURM_ARRAY_TASK_COUNT\")\n",
    "NETWORK_NAME = os.getenv(\"CI_COMMIT_SHA\")\n",
    "\n",
    "TASK_ID = int(TASK_ID) if TASK_ID is not None else None\n",
    "TASK_COUNT = int(TASK_COUNT) if TASK_COUNT is not None else None\n",
    "\n",
    "TASK_ID, TASK_COUNT, NETWORK_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = \"CI\" not in os.environ    \n",
    "DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    NETWORK_NAME = \"dcn_old_0,6bbf5b792c30570b8ab1a4c1b3426cdc6ad84446\"\n",
    "else:\n",
    "    assert NETWORK_NAME is not None\n",
    "    \n",
    "NETWORK_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if DEBUG:\n",
    "#     %load_ext autoreload\n",
    "#     %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DATAPKG`\n",
    "\n",
    "Can be skipped when `DEBUG = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPKG = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPKG['adjacency_net_v2'] = {\n",
    "    'decoy_discrimination_dataset': (\n",
    "        Path(os.environ['DATAPKG_OUTPUT_DIR'])\n",
    "        .joinpath(\n",
    "            \"adjacency-net-v2\",\n",
    "            \"v0.1\",\n",
    "            \"decoy_discrimination_dataset\",\n",
    "            \"f9e8ffb64f4d1335b075e656bc83d3dd1824d513\")\n",
    "    ),\n",
    "    'decoy_discrimination_dataset_rosetta': (\n",
    "        Path(os.environ['DATAPKG_OUTPUT_DIR'])\n",
    "        .joinpath(\n",
    "            \"adjacency-net-v2\",\n",
    "            \"v0.1\",\n",
    "            \"decoy_discrimination_dataset_rosetta\",\n",
    "            \"f9e8ffb64f4d1335b075e656bc83d3dd1824d513\")\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Can be skipped when `DEBUG = True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Parquet files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `decoy_discrimination_dataset_quick`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_files = sorted(\n",
    "    DATAPKG['adjacency_net_v2']['decoy_discrimination_dataset'].glob('*.parquet')\n",
    ")\n",
    "\n",
    "assert len(parquet_files) == 200\n",
    "parquet_files[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for file in parquet_files:\n",
    "    df = pq.read_table(file, use_pandas_metadata=True).to_pandas(integer_object_nulls=True)\n",
    "    dfs.append(df)\n",
    "\n",
    "decoy_discrimination_dataset_quick = pd.concat(dfs, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(decoy_discrimination_dataset_quick['unique_id'])) == len(decoy_discrimination_dataset_quick['unique_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decoy_discrimination_dataset_quick.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `decoy_discrimination_dataset_rosetta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_files = sorted(\n",
    "    DATAPKG['adjacency_net_v2']['decoy_discrimination_dataset_rosetta'].glob('*.parquet')\n",
    ")\n",
    "\n",
    "assert len(parquet_files) == 200\n",
    "parquet_files[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for file in parquet_files:\n",
    "    df = pq.read_table(file, use_pandas_metadata=True).to_pandas(integer_object_nulls=True)\n",
    "    dfs.append(df)\n",
    "\n",
    "decoy_discrimination_dataset_rosetta = pd.concat(dfs, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(decoy_discrimination_dataset_rosetta['unique_id'])) == len(decoy_discrimination_dataset_rosetta['unique_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decoy_discrimination_dataset_rosetta.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine into a single dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `decoy_discrimination_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Figure out why we need an inner join\n",
    "decoy_discrimination_dataset = (\n",
    "    decoy_discrimination_dataset_quick\n",
    "    .merge(\n",
    "        decoy_discrimination_dataset_rosetta[\n",
    "            ['unique_id'] + \n",
    "            [c for c in decoy_discrimination_dataset_rosetta.columns if c.startswith(\"rosetta_\")]],\n",
    "        on='unique_id', how='inner',\n",
    "        validate=\"1:1\",\n",
    "    )\n",
    ")\n",
    "\n",
    "assert len(set(decoy_discrimination_dataset['unique_id'])) == len(decoy_discrimination_dataset_quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(decoy_discrimination_dataset.head(1))\n",
    "print(len(decoy_discrimination_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run network\n",
    "\n",
    "Can be skipped when `DEBUG = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run trained_networks.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions using PDB adjacencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for network_name in reversed(NETWORK_NAME.split(',')):\n",
    "    decoy_discrimination_dataset[network_name] = (\n",
    "        helper.predict_with_network(\n",
    "            decoy_discrimination_dataset.rename(columns={\n",
    "                'residue_idx_1': 'adjacency_idx_1',\n",
    "                'residue_idx_2': 'adjacency_idx_2',\n",
    "            }),\n",
    "            network_state=TRAINED_NETWORKS[network_name]['network_state'],\n",
    "            network_info=TRAINED_NETWORKS[network_name]['network_info'],\n",
    "        )\n",
    "    )\n",
    "    assert decoy_discrimination_dataset[network_name].notnull().all(), network_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(decoy_discrimination_dataset, preserve_index=True)\n",
    "pq.write_table(\n",
    "    table,\n",
    "    OUTPUT_PATH.joinpath(f\"dataset.parquet\"),\n",
    "    version='2.0',\n",
    "    flavor='spark',\n",
    "    row_group_size=2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    decoy_discrimination_dataset_bak = decoy_discrimination_dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "parquet_file = pq.ParquetFile(OUTPUT_PATH.joinpath(f\"dataset.parquet\"))\n",
    "\n",
    "for row_group in range(parquet_file.num_row_groups):\n",
    "    df = (\n",
    "        parquet_file\n",
    "        .read_row_group(row_group, use_pandas_metadata=True)\n",
    "        .to_pandas(integer_object_nulls=True)\n",
    "    )\n",
    "    dfs.append(df)\n",
    "    \n",
    "decoy_discrimination_dataset = pd.concat(dfs, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    decoy_discrimination_dataset_bak\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    assert len(decoy_discrimination_dataset) == len(decoy_discrimination_dataset_bak)\n",
    "    assert (decoy_discrimination_dataset.index == decoy_discrimination_dataset_bak.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoy_discrimination_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(decoy_discrimination_dataset['structure_id'])) == 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `combined_stats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "columns = [\"feature\", \"correlation\", \"pvalue\", \"zscore\", \"top100\", \"top200\", \"top400\", \"top800\"]\n",
    "skipped_features = set()\n",
    "\n",
    "for c in set(columns) & set(globals()):\n",
    "    del globals()[c]\n",
    "\n",
    "for feature in decoy_discrimination_dataset.select_dtypes(include=['number']).columns:\n",
    "    if feature in [\"rmsd\"]:\n",
    "        continue\n",
    "    df = decoy_discrimination_dataset[[\"rmsd\", feature, \"decoy_name\"]].dropna().copy()\n",
    "\n",
    "    if len(df) != len(decoy_discrimination_dataset):\n",
    "        skipped_features.add(feature)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        correlation, pvalue = stats.spearmanr(df[\"rmsd\"], df[feature])\n",
    "    except FloatingPointError:\n",
    "        skipped_features.add(feature)\n",
    "        continue\n",
    "\n",
    "    df[\"zscore\"] = stats.zscore(df[feature])\n",
    "    zscore = df[df[\"decoy_name\"] == \"native.pdb\"][\"zscore\"].mean()\n",
    "\n",
    "    df_sorted = df.sample(frac=1).reset_index(drop=True).sort_values(feature, ascending=correlation > 0)\n",
    "    df_sorted[\"rank\"] = range(1, len(df) + 1)\n",
    "    rank = df_sorted[df_sorted[\"decoy_name\"] == \"native.pdb\"][\"rank\"]\n",
    "    top100 = sum(rank <= 100)\n",
    "    top200 = sum(rank <= 200)\n",
    "    top400 = sum(rank <= 400)\n",
    "    top800 = sum(rank <= 800)\n",
    "\n",
    "    data.append([globals()[c] for c in columns])\n",
    "\n",
    "combined_stats = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats[\"correlation_abs\"] = combined_stats[\"correlation\"].abs()\n",
    "combined_stats[\"zscore_abs\"] = combined_stats[\"zscore\"].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_stats.sort_values(\"zscore_abs\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(combined_stats, preserve_index=True)\n",
    "pq.write_table(\n",
    "    table,\n",
    "    OUTPUT_PATH.joinpath(f\"combined_stats.parquet\"),\n",
    "    version='2.0',\n",
    "    flavor='spark',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `per_structure_stats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "columns = ['query_id', 'feature', 'correlation', 'pvalue', 'rank', 'zscore']\n",
    "skipped_features = Counter()\n",
    "\n",
    "for c in set(columns) & set(globals()):\n",
    "    del globals()[c]\n",
    "\n",
    "for query_id, group in decoy_discrimination_dataset.groupby('structure_id'):\n",
    "    for feature in decoy_discrimination_dataset.select_dtypes(include=['number']).columns:\n",
    "        df = group.copy()\n",
    "        if feature in [\"rmsd\"]:\n",
    "            continue\n",
    "        try:\n",
    "            correlation, pvalue = stats.spearmanr(df[\"rmsd\"], df[feature])\n",
    "        except FloatingPointError:\n",
    "            skipped_features[feature] += 1\n",
    "            continue\n",
    "\n",
    "        df[\"zscore\"] = stats.zscore(df[feature])\n",
    "        zscore = df[df[\"decoy_name\"] == \"native.pdb\"][\"zscore\"].iloc[0]\n",
    "\n",
    "        df_sorted = group.sample(frac=1).reset_index(drop=True).sort_values(feature, ascending=correlation > 0)\n",
    "        df_sorted[\"rank\"] = range(1, len(df) + 1)\n",
    "        rank = df_sorted[df_sorted[\"decoy_name\"] == \"native.pdb\"][\"rank\"].iloc[0]\n",
    "        data.append([globals()[c] for c in columns])\n",
    "\n",
    "per_structure_stats = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_structure_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(per_structure_stats, preserve_index=True)\n",
    "pq.write_table(\n",
    "    table,\n",
    "    OUTPUT_PATH.joinpath(f\"per_structure_stats.parquet\"),\n",
    "    version='2.0',\n",
    "    flavor='spark',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `per_structure_stats_agg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def topk(s, k):\n",
    "    return sum(s <= k)\n",
    "\n",
    "def top1(s):\n",
    "    return topk(s, 1)\n",
    "\n",
    "def top5(s):\n",
    "    return topk(s, 5)\n",
    "\n",
    "def top10(s):\n",
    "    return topk(s, 10)\n",
    "\n",
    "def top20(s):\n",
    "    return topk(s, 20)\n",
    "\n",
    "\n",
    "per_structure_stats_agg = (\n",
    "    per_structure_stats\n",
    "    .groupby([\"feature\"])\n",
    "    .agg({\n",
    "        \"correlation\": \"mean\",\n",
    "        \"pvalue\": \"mean\",\n",
    "        \"zscore\": \"mean\",\n",
    "        \"rank\": [top1, top5, top10, top20]\n",
    "#         \"rank_top1\": lambda s: topk(s, 1),\n",
    "    })\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_structure_stats_agg.columns = per_structure_stats_agg.columns.values\n",
    "if isinstance(per_structure_stats_agg.columns[0], tuple):\n",
    "    per_structure_stats_agg = per_structure_stats_agg.rename(\n",
    "        columns=lambda c: c[0] if c[1] in [\"\", \"mean\"] else \"_\".join(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_structure_stats_agg[\"correlation_abs\"] = per_structure_stats_agg[\"correlation\"].abs()\n",
    "per_structure_stats_agg[\"zscore_abs\"] = per_structure_stats_agg[\"zscore\"].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_structure_stats_agg.sort_values(\"zscore_abs\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(per_structure_stats_agg, preserve_index=True)\n",
    "pq.write_table(\n",
    "    table,\n",
    "    OUTPUT_PATH.joinpath(f\"per_structure_stats_agg.parquet\"),\n",
    "    version='2.0',\n",
    "    flavor='spark',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = [\n",
    "    c for c in decoy_discrimination_dataset.columns\n",
    "    if c in [\"rmsd\", \"dope_score\", \"normalized_dope_score\"]\n",
    "    or c.startswith(\"modeller_\")\n",
    "    or c.startswith(\"rosetta_\")\n",
    "    or c in NETWORK_NAME.split(\",\")\n",
    "]\n",
    "\n",
    "target_columns = [\n",
    "    'rmsd',\n",
    "]\n",
    "\n",
    "feature_columns = [\n",
    "    \"rosetta_relax_total_score\",\n",
    "    \"rosetta_score_total_score\",\n",
    "    \"normalized_dope_score\",\n",
    "    \"ga341_score_1\",\n",
    "    \"ga341_score_2\",\n",
    "    \"ga341_score_3\",\n",
    "    \"ga341_score_4\",\n",
    "    \"ga341_score_5\",\n",
    "    \"ga341_score_6\",\n",
    "    \"ga341_score_7\",\n",
    "]\n",
    "\n",
    "network_columns = NETWORK_NAME.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `combined_stats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = feature_columns + network_columns\n",
    "data = combined_stats.set_index(\"feature\").loc[features].reset_index()\n",
    "labels = [c if len(c) < 32 or any(s in c for s in [' ', '_', '-']) else c[:7] for c in features]\n",
    "colors = [cmap(1)] * len(feature_columns) + [cmap(2)] * len(network_columns)\n",
    "\n",
    "for i, feature in enumerate([\"correlation_abs\", \"zscore_abs\", \"top100\"]):\n",
    "    fig, axes = plt.subplots(dpi=100, constrained_layout=True)\n",
    "    ax = axes\n",
    "    ax.bar(\"feature\", feature, data=data, tick_label=labels, color=colors)\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(90)\n",
    "#     ax.set_ylim(0, 0.8)\n",
    "    ax.set_ylabel(feature)\n",
    "    plt.savefig(OUTPUT_PATH.joinpath(f\"combined_stats_{feature}.svg\"), dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `per_structure_stats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = feature_columns + network_columns\n",
    "\n",
    "data = (\n",
    "    per_structure_stats\n",
    "    .groupby(\"feature\")\n",
    "    .agg(tuple)\n",
    "    .loc[columns]\n",
    "    .reset_index()\n",
    ")\n",
    "data.loc[data[\"feature\"].isin(network_columns), \"correlation\"] = (\n",
    "    data.loc[data[\"feature\"].isin(network_columns), \"correlation\"]\n",
    "    .apply(lambda row: tuple(-r for r in row))\n",
    ")\n",
    "data.loc[data[\"feature\"].isin(feature_columns), \"zscore\"] = (\n",
    "    data.loc[data[\"feature\"].isin(feature_columns), \"zscore\"]\n",
    "    .apply(lambda row: tuple(-r for r in row))\n",
    ")\n",
    "\n",
    "labels = [c if len(c) < 32 or any(s in c for s in [' ', '_', '-']) else c[:7] for c in columns]\n",
    "\n",
    "cmap = plt.get_cmap(\"Set1\")\n",
    "colors = [cmap(1)] * len(feature_columns) + [cmap(2)] * len(network_columns)\n",
    "\n",
    "boxplot_rc = {\n",
    "    \"boxplot.boxprops.linewidth\": 1.5,\n",
    "    'boxplot.whiskerprops.linewidth': 1.5,\n",
    "    \"boxplot.meanprops.linewidth\": 1.5,\n",
    "    \"boxplot.medianprops.color\": 'k',\n",
    "}\n",
    "\n",
    "for i, feature in enumerate([\"correlation\", \"zscore\", \"rank\"]):\n",
    "    fig, axes = plt.subplots(dpi=100, constrained_layout=True)\n",
    "    ax = axes\n",
    "    with plt.rc_context(rc=boxplot_rc):\n",
    "        ax.boxplot(feature, data=data, labels=labels, sym=\"\")\n",
    "    for feature_idx, points in enumerate(data[feature]):\n",
    "        jitter = np.random.normal(feature_idx + 1, 0.05, len(points))\n",
    "        ax.scatter(jitter, points, c=[colors[feature_idx]], alpha=0.3)\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(90)\n",
    "    # ax.set_ylim(0, 0.8)\n",
    "    ax.set_ylabel(feature)\n",
    "    if feature in [\"rank\"]:\n",
    "        ax.invert_yaxis()\n",
    "    plt.savefig(OUTPUT_PATH.joinpath(f\"per_structure_stats_{feature}.svg\"), dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `per_structure_stats_agg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_columns + network_columns\n",
    "data = per_structure_stats_agg.set_index(\"feature\").loc[features].reset_index()\n",
    "labels = [c if len(c) < 32 or any(s in c for s in [' ', '_', '-']) else c[:7] for c in features]\n",
    "colors = [cmap(1)] * len(feature_columns) + [cmap(2)] * len(network_columns)\n",
    "\n",
    "for i, feature in enumerate([\"correlation_abs\", \"zscore_abs\", \"rank_top1\"]):\n",
    "    fig, axes = plt.subplots(dpi=100, constrained_layout=True)\n",
    "    ax = axes\n",
    "    ax.bar(\"feature\", feature, data=data, tick_label=labels, color=colors)\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(90)\n",
    "#     ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel(feature)\n",
    "    plt.savefig(OUTPUT_PATH.joinpath(f\"per_structure_stats_agg_{feature}.svg\"), dpi=300, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "505px",
    "left": "24px",
    "top": "143px",
    "width": "331px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
