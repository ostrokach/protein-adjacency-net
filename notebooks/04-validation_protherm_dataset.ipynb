{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import itertools\n",
    "import importlib\n",
    "import multiprocessing\n",
    "import os\n",
    "import os.path as op\n",
    "import pickle\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import seaborn as sns\n",
    "import sqlalchemy as sa\n",
    "from scipy import stats\n",
    "\n",
    "from kmtools import py_tools, sequence_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PATH = Path.cwd().joinpath('..', 'src').resolve(strict=True)\n",
    "\n",
    "if SRC_PATH.as_posix() not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH.as_posix())\n",
    "\n",
    "import helper\n",
    "importlib.reload(helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_PATH = Path('validation_protherm_dataset')\n",
    "NOTEBOOK_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = Path(os.getenv('OUTPUT_DIR', NOTEBOOK_PATH.name)).resolve()\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = subprocess.run([\"git\", \"rev-parse\", \"--short\", \"HEAD\"], stdout=subprocess.PIPE)\n",
    "GIT_REV = proc.stdout.decode().strip()\n",
    "GIT_REV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_ID = os.getenv(\"SLURM_ARRAY_TASK_ID\")\n",
    "TASK_COUNT = os.getenv(\"ORIGINAL_ARRAY_TASK_COUNT\") or os.getenv(\"SLURM_ARRAY_TASK_COUNT\")\n",
    "NETWORK_NAME = os.getenv(\"CI_COMMIT_SHA\")\n",
    "\n",
    "TASK_ID = int(TASK_ID) if TASK_ID is not None else None\n",
    "TASK_COUNT = int(TASK_COUNT) if TASK_COUNT is not None else None\n",
    "\n",
    "TASK_ID, TASK_COUNT, NETWORK_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = \"CI\" not in os.environ    \n",
    "DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    NETWORK_NAME = \",\".join([\n",
    "        \"4a4320bd49d7b25fe9018c1b40426a45b1642565\",  # test50-cedar\n",
    "\n",
    "        \"a195c0e680a6dec151ea19de4735a6577dde399b\",  # test50\n",
    "        \"654c84ccb1bc0ecd0fa5d16c31ab3bfe21d45c8b\",  # test51\n",
    "\n",
    "        \"a3556373181d42ce0985e8d2146cfd5b0788502e\",  # test65\n",
    "\n",
    "        \"7b4ff1af3ec63a01fa415435420c554be1fecbb0\",  # test74\n",
    "        \"55374d153b6646f041dde6ee49ab751ef2d833aa\",\n",
    "        \"a7c0444c959a656be8ff6acbf88ef36fd02c59fc\",\n",
    "        \"8aa30e0188404d429ecdc6357205bc6924fb7759\",\n",
    "        \"9b134475368bd81fa1de197f8180ff1c82ce8727\",\n",
    "        \"4e2968caa1d0a9cb9fdee0488a3ede2283bce316\",\n",
    "        \"b22189e7357853cc5c76c9435b1c0497030761dd\",\n",
    "    ])\n",
    "else:\n",
    "    assert NETWORK_NAME is not None\n",
    "    \n",
    "NETWORK_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if DEBUG:\n",
    "#     %load_ext autoreload\n",
    "#     %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `DATAPKG`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPKG = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPKG['protherm_validaton_dataset'] = (\n",
    "    Path(os.environ['DATAPKG_OUTPUT_DIR'])\n",
    "    .joinpath(\"adjacency-net-v2\", \"v0.2\", \"protherm_dataset\", \"protherm_validaton_dataset.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = (\n",
    "    DATAPKG['protherm_validaton_dataset']\n",
    "    .resolve(strict=True)\n",
    ")\n",
    "input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pq.read_table(input_file).to_pandas()\n",
    "input_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.spearmanr(input_df['cartesian_ddg_beta_nov16_cart_1'].values, input_df['ddg_exp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run trained_networks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_sequence(row):\n",
    "    sequence = row['sequence']\n",
    "    wt = row['mutation'][0]\n",
    "    pos = int(row['mutation'][1:-1])\n",
    "    mut = row['mutation'][-1]\n",
    "    sequence_mut = sequence[:pos - 1] + mut + sequence[pos:]\n",
    "    assert len(sequence) == len(sequence_mut)\n",
    "    return sequence_mut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['sequence'] = input_df['qseq']\n",
    "input_df['sequence_mut'] = input_df.apply(mutate_sequence, axis=1)\n",
    "# input_df['sequence_mut'] = input_df['qseq_mutation']\n",
    "input_df['adjacency_idx_1'] = input_df['residue_idx_1_corrected']\n",
    "input_df['adjacency_idx_2'] = input_df['residue_idx_2_corrected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network_name in NETWORK_NAME.split(','):\n",
    "    input_df[f'{network_name}_wt'] = helper.predict_with_network(\n",
    "        input_df[['sequence', 'adjacency_idx_1', 'adjacency_idx_2', 'distances']]\n",
    "            .copy(),\n",
    "        network_state=TRAINED_NETWORKS[network_name]['network_state'],\n",
    "        network_info=TRAINED_NETWORKS[network_name]['network_info'],\n",
    "    )\n",
    "    input_df[f'{network_name}_mut'] = helper.predict_with_network(\n",
    "        input_df[['sequence_mut', 'adjacency_idx_1', 'adjacency_idx_2', 'distances']]\n",
    "            .rename(columns={'sequence_mut': 'sequence'}).copy(),\n",
    "        network_state=TRAINED_NETWORKS[network_name]['network_state'],\n",
    "        network_info=TRAINED_NETWORKS[network_name]['network_info'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network_name in NETWORK_NAME.split(','):\n",
    "    input_df[f'{network_name}_change'] = (\n",
    "        input_df[f'{network_name}_mut'] -\n",
    "        input_df[f'{network_name}_wt']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(input_df, preserve_index=True)\n",
    "pq.write_table(\n",
    "    table,\n",
    "    OUTPUT_PATH.joinpath(\"validation_protherm_dataset.parquet\"),\n",
    "    version='2.0',\n",
    "    flavor='spark',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ref = [\n",
    "    ('Provean', 0.25, None),\n",
    "    ('FoldX', 0.48, None),\n",
    "    ('ELASPIC', 0.54, None),\n",
    "    ('Rosetta', 0.59, None),  # cartesian_ddg_beta_nov16_cart_1\n",
    "]\n",
    "\n",
    "data_net = []\n",
    "\n",
    "for network_name in NETWORK_NAME.split(','):\n",
    "    corr, pvalue = stats.spearmanr(\n",
    "        input_df[f'{network_name}_change'],\n",
    "        -input_df['ddg_exp']\n",
    "    )\n",
    "    data_net.append((network_name, corr, pvalue))\n",
    "    \n",
    "# data_net.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"Set1\")\n",
    "\n",
    "feature_names = {}\n",
    "\n",
    "df = pd.DataFrame(data_ref + data_net, columns=['feature', 'correlation', 'pvalue'])\n",
    "df\n",
    "\n",
    "# fg, axs = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "with plt.rc_context(rc={'figure.figsize': (8, 4), 'font.size': 13}):\n",
    "    x = np.arange(len(df))\n",
    "    c = [cmap(2) if f in NETWORK_NAME.split(',') else cmap(1) for f in df['feature']]\n",
    "    plt.bar(x, df['correlation'], color=c)\n",
    "    plt.xticks(x, [feature_names.get(f, f[:7]) for f in df['feature'].values], rotation=45)\n",
    "    plt.ylim(0.4, 1)\n",
    "    plt.ylabel(\"Correlation\")\n",
    "    plt.title(\"Predicting Protherm ΔΔG\")\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_PATH.joinpath(\"validation_protherm_correlations.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.savefig(OUTPUT_PATH.joinpath(\"validation_protherm_correlations.svg\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "424px",
    "left": "26px",
    "top": "141px",
    "width": "187px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
