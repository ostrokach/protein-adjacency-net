image: registry.gitlab.com/ostrokach-docker/conda:latest

stages:
  - init
  - notebooks-01
  - deploy


# === Variables ===

variables:
  PROJECT_NAME: "adjacency-net"
  PROJECT_VERSION: "0.1"
  DOCS_SECRET_KEY: "SWKhaBJiG8O53MTcw97h1vRjVgimQCb4mzTIH4H8dD10vrb6NWOUantGWhqHMoY7"

.niagara-envs: &niagara-envs
  SBATCH_ARGS: "--account=def-pmkim"
  # SBATCH_EXTRA_ARGS: "--time 12:00:00 --array=1-1"

.graham-envs: &graham-envs
  SBATCH_ARGS: "--account=def-pmkim --exclusive --mem=0"
  # SBATCH_EXTRA_ARGS: "--time 12:00:00 --array=1-1"

.cedar-envs: &cedar-envs
  SBATCH_ARGS: "--account=rrg-pmkim --exclusive --mem=0"
  # SBATCH_EXTRA_ARGS: "--time 12:00:00 --array=1-1"


# === Basic GitLab runner tests ===

.test: &test
  stage: init
  script:
    - echo "starting test..."
    - find .
    - sleep 1
    - mkdir -p some-folder
    - echo "hello world" > some-folder/greeting.txt
    - echo "$(date --iso-8601=seconds)" > some-folder/time.txt
    - echo "done"
  artifacts:
    paths:
      - some-folder

test-niagara:
  tags:
    - niagara
  <<: *test

test-ssh:
  tags:
    - compute-canada
    - ssh
  <<: *test


# === Conda environment ===

create-conda-environment:
  stage: init
  script:
    - conda env remove -q -y -n ${CI_PROJECT_NAME}-ci || true
    - conda env create -q -n ${CI_PROJECT_NAME}-ci -f environment.yaml


# === Batch jobs ===

# sbatch

.sbatch-setup: &sbatch-setup
  before_script:
    # Make sure all required environment variables have been set
    - if [[ -z ${NOTEBOOK_NAME} || -z ${DATA_DIR} || -z ${DATABIN_DIR} || -z ${CI_PROJECT_NAME} || -z ${CI_COMMIT_SHA} || -z ${CI_JOB_NAME} || -z ${CI_PROJECT_PATH_SLUG} ]] ; then
      echo "Not all required environment variables have been set!" ;
      exit -1 ;
      fi
    # Create conda environment
    - conda activate ${CI_PROJECT_NAME}-ci
    # Set output directory
    - export OUTPUT_DIR=${DATABIN_DIR}/${CI_PROJECT_NAME}/${CI_COMMIT_SHA}/${CI_JOB_NAME}
    - mkdir -p "${OUTPUT_DIR}"
    - echo "export OUTPUT_DIR=${OUTPUT_DIR}" >> env.sh

.sbatch: &sbatch
  script:
    - sbatch
      --time=12:00:00
      --nodes=1
      --job-name=${NOTEBOOK_NAME}
      --chdir=`pwd`
      --output=${OUTPUT_DIR}/sbatch-%A-%a.log
      --export=ALL
      --wait
      ${SBATCH_ARGS}
      ${SBATCH_EXTRA_ARGS}
      ${SBATCH_SCRIPT} |
      tee sbatch.out

.sbatch-teardown: &sbatch-teardown
  after_script:
    # Set JOB_ID
    - JOB_ID=$(rg "Submitted batch job" sbatch.out | rg -o '\d+$')
    - echo "export JOB_ID=${JOB_ID}" >> env.sh
    # Load environment variables from previous stages
    - source env.sh
    # Remove conda environment
    - conda deactivate
    - conda env remove -q -y -n ${CI_PROJECT_NAME}-ci
    # Save job output
    - mkdir -p output
    - cp -al ${OUTPUT_DIR} output/$(basename ${OUTPUT_DIR})

.sbatch-output: &sbatch-output
  script:
    - cat env.sh
    - source env.sh
    - ./scripts/wait-for-job-to-finish.sh
    - mkdir -p output
    - cp -al ${OUTPUT_DIR} output/$(basename ${OUTPUT_DIR})
    - (cd output; ln -s )
  artifacts:
    paths:
      - output

# Jobs

basic_tests:
  stage: notebooks-01
  tags:
    - niagara
  variables:
    <<: *niagara-envs
    SBATCH_SCRIPT: "./scripts/run-notebook.sh"
    SBATCH_EXTRA_ARGS: "--array=1-2"
    NOTEBOOK_NAME: "01-basic_tests"
  <<: [*sbatch-setup, *sbatch, *sbatch-teardown]
  artifacts:
    paths:
      - env.sh
      - output
    when: always
  when: manual


# === Pages ===

pages:
  stage: deploy
  before_script:
    # Install conda packages
    - conda install -yq
      git python pip ipython jupyter ipykernel pypandoc
    # Install pip packages
    - pip install -q
      sphinx recommonmark sphinx_bootstrap_theme
  script:
    # Generate notebooks.csv
    - ./scripts/create_notebook_table.py -i notebooks/ -o docs/notebooks.csv
    # Build pages
    - sphinx-build docs public/$DOCS_SECRET_KEY
    # Convert notebooks
    - mkdir -p public/$DOCS_SECRET_KEY/notebooks
    - ./scripts/convert_notebooks.sh notebooks/ public/$DOCS_SECRET_KEY/notebooks/
  artifacts:
    paths:
    - public
