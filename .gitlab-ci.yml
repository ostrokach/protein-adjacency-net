image: registry.gitlab.com/kimlab/linux-anvil:latest

stages:
  - lint
  - build
  - test
  - deploy

# === Variables ===

variables:
  PACKAGE_VERSION: 0.1.9.dev

.py36: &py36
  PYTHON_VERSION: "3.6"

# === Configurations ===

.conda_configure: &conda_configure
  cache:
    key: ${CI_JOB_NAME}-mod1
    paths:
      - .conda_packages/*.tar.bz2
      - .conda_packages/urls.txt
  before_script:
    # Conda environment variables
    - export CONDA_PKGS_DIRS="${CI_PROJECT_DIR}/.conda_packages"
    # Make conda cache and bld folders
    - mkdir -p "${CI_PROJECT_DIR}/conda-bld" "${CONDA_PKGS_DIRS}"
    - rm -rf ${CONDA_PKGS_DIRS}/${CI_PROJECT_NAME}-*
    # Conda configure
    - conda config --set channel_priority true
    - conda config --append pkgs_dirs "${CONDA_PKGS_DIRS}"
    - conda config --append channels pytorch
    - conda config --append channels ostrokach-forge
    - conda config --append channels bioconda
    - case "${PACKAGE_VERSION}" in
      *dev*)
        conda config --append channels kimlab;
        conda config --append channels kimlab/label/dev;
        conda config --append channels ostrokach;
        conda config --append channels ostrokach/label/dev;
      ;;
      *)
        conda config --append channels kimlab;
        conda config --append channels ostrokach;
      ;;
      esac

# === Lint ===

lint:
  stage: lint
  <<: [*conda_configure]
  variables:
    <<: [*py36]
  script:
    - conda install -yq "python=${PYTHON_VERSION}" isort flake8 mypy
    - python -m isort -p "${CI_PROJECT_NAME}" -c
    - python -m flake8
    - python -m mypy -p "${CI_PROJECT_NAME}" || true

# === Build ===

.build: &build
  stage: build
  script:
    # Build conda packages
    - cd "${CI_PROJECT_DIR}/.conda"
    - conda build .
      --no-test
      --python $PYTHON_VERSION
      --output-folder "${CI_PROJECT_DIR}/conda-bld"
  artifacts:
    paths:
      - conda-bld

build-py36:
  <<: [*conda_configure, *build]
  variables:
    <<: [*py36]

# === Test ===

.test: &test
  stage: test
  script:
    # Restore built packages
    - cp -r $CI_PROJECT_DIR/conda-bld/* /opt/conda/conda-bld/
    - conda index /opt/conda/conda-bld/
    # Run tests
    - cd $CI_PROJECT_DIR/.conda
    - conda build .
      --test
      --python $PYTHON_VERSION
  coverage: /^TOTAL.* (\d+\%)/
  artifacts:
    paths:
      - environment-py${PYTHON_VERSION/./}.yml

test-py36:
  <<: [*conda_configure, *test]
  variables:
    <<: [*py36]
  dependencies:
    - build-py36

# === Docs ===

docs:
  stage: test
  <<: [*conda_configure]
  script:
    # Restore built packages
    - cp -r $CI_PROJECT_DIR/conda-bld/* /opt/conda/conda-bld/
    - conda index /opt/conda/conda-bld/
    # Install required packages
    - conda install -yq --use-local "python=$PYTHON_VERSION" ${CI_PROJECT_NAME}
    - conda install -yq nbconvert ipython ipykernel pandoc
    - pip install -q sphinx sphinx_rtd_theme recommonmark nbsphinx
    # Build docs
    - sphinx-build docs public
  dependencies:
    - build-py36
  variables:
    <<: [*py36]
  artifacts:
    paths:
      - public
  except:
    - triggers

# === Deploy ===

.deploy: &deploy
  stage: deploy
  before_script:
    - conda install twine -yq --no-channel-priority
  script:
    # Rename wheels from `-linux_x86_64.whl` to `-manylinux1_x86_64.whl`
    # so that they can be uploaded to PyPI.
    - for i in $CI_PROJECT_DIR/conda-bld/linux-64/*.whl ; do
      echo $i;
      mv "${i}" "${i%%-linux_x86_64.whl}-manylinux1_x86_64.whl";
      done
    # Development releases go to the Anaconda dev channel
    - if [[ ${PACKAGE_VERSION} = *"dev"* ]] ; then
        anaconda -t $ANACONDA_TOKEN upload $CI_PROJECT_DIR/conda-bld/linux-64/*.tar.bz2 -u ${CI_PROJECT_NAMESPACE} --label dev --force ;
       fi
    # Tagged releases go to the Anaconda and PyPI main channels
    - if [[ -n ${CI_COMMIT_TAG} ]] ; then
        anaconda -t $ANACONDA_TOKEN upload $CI_PROJECT_DIR/conda-bld/linux-64/*.tar.bz2 -u ${CI_PROJECT_NAMESPACE} ;
        twine upload $CI_PROJECT_DIR/conda-bld/linux-64/*.whl ;
      fi

deploy-py36:
  <<: *deploy
  dependencies:
    - build-py36

# === Pages ===

pages:
  stage: deploy
  before_script:
    - sudo yum install -y -q unzip
    - curl -s -L https://github.com/stedolan/jq/releases/download/jq-1.5/jq-linux64 -o jq
    - md5sum jq | grep 6a342dbb17b2f2ea4ec0e64d2157614d
    - sudo mv jq /usr/local/bin/jq
    - sudo chmod +x /usr/local/bin/jq
  script:
    # Create docs folder for the current version
    - mv public "v${PACKAGE_VERSION%.dev}"
    - mkdir public
    - mv "v${PACKAGE_VERSION%.dev}" public/
    # Create docs folder for each tag
    - echo "${PATH}"
    - |
      curl -s -L --header "JOB-TOKEN: ${CI_JOB_TOKEN}" \
        "https://gitlab.com/api/v4/projects/kimlab%2Fpagnn/jobs?scope=success" |
      jq --raw-output '.[] | select(.tag == true) | select(.name == "docs") | "\(.ref) \(.id)"' |
      while read tag job_id ; do
        echo $tag $job_id ;
        curl -s -L --header "JOB-TOKEN: ${CI_JOB_TOKEN}" \
          "https://gitlab.com/kimlab/pagnn/-/jobs/${job_id}/artifacts/download" \
          -o artifact-${tag}.zip || continue ;
        unzip -q artifact-${tag}.zip -d public || continue ;
        rm -rf public/${tag} ;
        mv public/public public/${tag} ;
      done
    # Create index file
    # TODO:
  dependencies:
    - docs
  artifacts:
    paths:
      - public
  only:
    - master
    - tags
  except:
    - triggers
