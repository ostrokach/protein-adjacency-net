image: registry.gitlab.com/ostrokach-docker/conda:latest

stages:
  - init
  - notebooks-03
  - notebooks-04
  - deploy


# === Variables ===

variables:
  PROJECT_VERSION: "0.1"
  DOCS_SECRET_KEY: "SWKhaBJiG8O53MTcw97h1vRjVgimQCb4mzTIH4H8dD10vrb6NWOUantGWhqHMoY7"
  PYPROJECT_GIT_REV: "98c11f5e9490a12017d7202ac377345f59aa3b99"
  CONDA_ENVIRONMENT_NAME: ci-${CI_PROJECT_PATH_SLUG}-${CI_COMMIT_REF_SLUG}

.niagara-envs: &niagara-envs
  # Uses all memory on node by default
  SBATCH_ARGS: "--account=def-pmkim"
  # SBATCH_EXTRA_ARGS: "--time 12:00:00 --array=1-1"

.graham-envs: &graham-envs
  SBATCH_ARGS: "--account=def-pmkim --exclusive --mem=0"
  # SBATCH_EXTRA_ARGS: "--time 12:00:00 --array=1-1"

.cedar-envs: &cedar-envs
  SBATCH_ARGS: "--account=rrg-pmkim --exclusive --mem=0 --constraint=skylake"
  # SBATCH_EXTRA_ARGS: "--time 12:00:00 --array=1-1"

.cluster-tags: &cluster-tags
  tags:
    - cedar-ssh

.cluster-envs: &cluster-envs
  SBATCH_SCRIPT: "./scripts/qsub.sh"
  <<: *cedar-envs


# === Basic GitLab runner tests ===

.test: &test
  stage: init
  script:
    - echo "starting test..."
    - find .
    - sleep 1
    - mkdir -p some-folder
    - echo "hello world" > some-folder/greeting.txt
    - echo "$(date --iso-8601=seconds)" > some-folder/time.txt
    - echo "done"
  artifacts:
    paths:
      - some-folder
  only:
    variables:
      - $JOBS_TO_RUN =~ /\A(.*,\s?)*tests(,\s?.*)*\z/i
      - $CI_COMMIT_MESSAGE =~ /\[ci jobs?:\s*(.*,\s?)*tests(,\s?.*)*\]/i

test-niagara-ssh:
  <<: *test
  tags:
    - niagara-ssh

test-graham-ssh:
  <<: *test
  tags:
    - graham-ssh

test-cedar-ssh:
  <<: *test
  tags:
    - cedar-ssh


# === Conda environment ===

create-conda-environment:
  stage: init
  <<: *cluster-tags
  script:
    - conda env update -q -n ${CONDA_ENVIRONMENT_NAME} -f environment-lock.yaml
    - source activate ${CONDA_ENVIRONMENT_NAME}
    - pip install -U git+https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.com/kimlab/pagnn.git@${PYPROJECT_GIT_REV}
  only:
    variables:
      - $JOBS_TO_RUN =~ /\A(.*,\s?)*create-conda-environment(,\s?.*)*\z/i
      - $CI_COMMIT_MESSAGE =~ /\[ci jobs?:\s*(.*,\s?)*create-conda-environment(,\s?.*)*\]/i
    changes:
      # Not working together with variables ATM
      - environment-lock.yaml


# === Batch jobs ===

.sbatch-setup: &sbatch-setup
  before_script:
    # Make sure all required environment variables have been set
    - REQUIRED_VARS=(
      CONDA_ENVIRONMENT_NAME
      DATAPKG_INPUT_DIR
      DATAPKG_OUTPUT_DIR
      CI_PROJECT_NAME
      CI_COMMIT_REF_SLUG
      CI_JOB_NAME
      CI_JOB_ID
      )
    - for var in ${REQUIRED_VARS[*]} ; do
      if [[ -z "${!var}" ]] ; then
      echo "Environment variable '${var}' has not been set!" ;
      exit -1 ;
      fi ;
      done
    # Activate conda environment
    - source activate ${CONDA_ENVIRONMENT_NAME}
    # Set output directory
    - GIT_REV=$(git rev-parse --short HEAD)
    - if [[ -z ${NETWORK_NAME} ]] ;
      then NETWORK_NAME=${GIT_REV} ;
      fi
    - export OUTPUT_DIR=${DATAPKG_OUTPUT_DIR}/${CI_PROJECT_NAME}/${CI_COMMIT_SHA}/${CI_JOB_NAME}
    - export OUTPUT_DIR_FINAL=${DATAPKG_OUTPUT_DIR}/${CI_PROJECT_NAME}/${CI_COMMIT_REF_SLUG}/${CI_JOB_NAME}/${NETWORK_NAME}
    - echo "export OUTPUT_DIR=${OUTPUT_DIR}" | tee -a env.sh
    - echo "export OUTPUT_DIR_FINAL=${OUTPUT_DIR_FINAL}" | tee -a env.sh
    - if [[ -d ${OUTPUT_DIR} || -d ${OUTPUT_DIR_FINAL} && -z ${ORIGINAL_ARRAY_TASK_COUNT} ]] ; then
      echo "Either OUTPUT_DIR or OUTPUT_DIR_FINAL already exist!" ;
      exit -1 ;
      fi
    - mkdir -p "${OUTPUT_DIR}" "${OUTPUT_DIR}/logs" "${OUTPUT_DIR}/notebooks"

.sbatch: &sbatch
  script:
    - sbatch
      --nodes=1
      --ntasks-per-node=1
      --job-name=${CI_JOB_NAME}
      --mail-user=alexey.strokach@kimlab.org
      --mail-type=ALL
      --chdir=`pwd`
      --output=${OUTPUT_DIR}/logs/sbatch-${CI_JOB_ID}-%N-%A-%a.log
      --export=ALL
      --wait
      ${SBATCH_ARGS}
      ${SBATCH_EXTRA_ARGS}
      ${SBATCH_SCRIPT} |
      tee sbatch.out

.sbatch-teardown: &sbatch-teardown
  after_script:
    # Activate conda environment
    - source activate ${CONDA_ENVIRONMENT_NAME}
    # Set JOB_ID
    - JOB_ID=$(rg "Submitted batch job" sbatch.out | rg -o '\d+$')
    - echo "export JOB_ID=${JOB_ID}" >> env.sh
    # Load environment variables from previous stages
    - source env.sh
    - cp env.sh ${OUTPUT_DIR}/env-${CI_COMMIT_SHA}.sh
    # Save job output to GitLab CI
    - mkdir -p output
    - rsync -a --link-dest=${OUTPUT_DIR} --include="notebooks/***" --include="logs/***" --exclude="*" ${OUTPUT_DIR}/ output
    # Update job output to ${OUTPUT_DIR_FINAL}
    - mkdir -p ${OUTPUT_DIR_FINAL}
    - rsync -a --link-dest=${OUTPUT_DIR} ${OUTPUT_DIR}/ ${OUTPUT_DIR_FINAL}
    # Display job output
    - for file in output/logs/*.log ; do
      echo -e "\e[1m\e[35m${file}\e[0m" ;
      cat $file ;
      done
    # Display job resource consumption
    - sacct -j ${JOB_ID} --fields JobID,User,Account,AllocNodes,Start,End,Elapsed,AllocTRES,CPUTime,NodeList,ExitCode,State,SystemCPU,UserCPU,TotalCPU,AveDiskRead,MaxDiskRead,AveRSS,MaxRSS,AveVMSize,MaxVMSize -p --delimiter \| | xsv table -d '|'
  artifacts:
    paths:
      - env.sh
      - output
    when: always

.sbatch-output: &sbatch-output
  script:
    - cat env.sh
    - source env.sh
    - ./scripts/wait-for-job-to-finish.sh
    - mkdir -p output
    - cp -al ${OUTPUT_DIR} output/$(basename ${OUTPUT_DIR})
    - (cd output; ln -s )
  artifacts:
    paths:
      - output

# === User code ===

.notebook: &notebook
  <<: *cluster-tags
  <<: [*sbatch-setup, *sbatch, *sbatch-teardown]

train_network:
  <<: *notebook
  stage: notebooks-03
  variables:
    <<: *cluster-envs
    SBATCH_SCRIPT: "./scripts/train_network.sh"
    SBATCH_TIMELIMIT: "3:00:00"
    SBATCH_EXTRA_ARGS: "--array=0-10%1 --time ${SBATCH_TIMELIMIT} "
  only:
    variables:
      - $JOBS_TO_RUN =~ /\A(.*,\s?)*train_network(,\s?.*)*\z/i
      - $CI_COMMIT_MESSAGE =~ /\[ci jobs?:\s*(.*,\s?)*train_network(,\s?.*)*\]/i

validation_training_stats:
  <<: *notebook
  stage: notebooks-04
  variables:
    <<: *cluster-envs
    NOTEBOOK_NAME: "04-validation_training_stats"
    SBATCH_EXTRA_ARGS: "--time 3:00:00 "
  only:
    variables:
      - $JOBS_TO_RUN =~ /\A(.*,\s?)*validation_training_stats(,\s?.*)*\z/i
      - $CI_COMMIT_MESSAGE =~ /\[ci jobs?:\s*(.*,\s?)*validation_training_stats(,\s?.*)*\]/i
      - $JOBS_TO_RUN =~ /\A(.*,\s?)*validate_network(,\s?.*)*\z/i
      - $CI_COMMIT_MESSAGE =~ /\[ci jobs?:\s*(.*,\s?)*validate_network(,\s?.*)*\]/i

validation_protherm_dataset:
  <<: *notebook
  stage: notebooks-04
  variables:
    <<: *cluster-envs
    NOTEBOOK_NAME: "04-validation_protherm_dataset"
    SBATCH_EXTRA_ARGS: "--time 3:00:00 "
  only:
    variables:
      - $JOBS_TO_RUN =~ /\A(.*,\s?)*validation_protherm_dataset(,\s?.*)*\z/i
      - $CI_COMMIT_MESSAGE =~ /\[ci jobs?:\s*(.*,\s?)*validation_protherm_dataset(,\s?.*)*\]/i
      - $JOBS_TO_RUN =~ /\A(.*,\s?)*validate_network(,\s?.*)*\z/i
      - $CI_COMMIT_MESSAGE =~ /\[ci jobs?:\s*(.*,\s?)*validate_network(,\s?.*)*\]/i

validation_homology_models:
  <<: *notebook
  stage: notebooks-04
  variables:
    <<: *cluster-envs
    NOTEBOOK_NAME: "04-validation_homology_models"
    SBATCH_EXTRA_ARGS: "--time 3:00:00 "
  only:
    variables:
      - $JOBS_TO_RUN =~ /\A(.*,\s?)*validation_homology_models(,\s?.*)*\z/i
      - $CI_COMMIT_MESSAGE =~ /\[ci jobs?:\s*(.*,\s?)*validation_homology_models(,\s?.*)*\]/i
      - $JOBS_TO_RUN =~ /\A(.*,\s?)*validate_network(,\s?.*)*\z/i
      - $CI_COMMIT_MESSAGE =~ /\[ci jobs?:\s*(.*,\s?)*validate_network(,\s?.*)*\]/i

validation_remote_homology_detection:
  <<: *notebook
  stage: notebooks-04
  variables:
    <<: *cluster-envs
    NOTEBOOK_NAME: "04-validation_remote_homology_detection"
    SBATCH_EXTRA_ARGS: "--time 3:00:00 "
  only:
    variables:
      - $JOBS_TO_RUN =~ /\A(.*,\s?)*validation_remote_homology_detection(,\s?.*)*\z/i
      - $CI_COMMIT_MESSAGE =~ /\[ci jobs?:\s*(.*,\s?)*validation_remote_homology_detection(,\s?.*)*\]/i
      - $JOBS_TO_RUN =~ /\A(.*,\s?)*validate_network(,\s?.*)*\z/i
      - $CI_COMMIT_MESSAGE =~ /\[ci jobs?:\s*(.*,\s?)*validate_network(,\s?.*)*\]/i

# === Pages ===

pages:
  stage: deploy
  before_script:
    # Install conda packages
    - conda install -y -q
      git pip ipython jupyter ipykernel pypandoc
    # Install pip packages
    - pip install -q
      sphinx recommonmark sphinx_bootstrap_theme
  script:
    # Generate notebooks.csv
    - ./scripts/create_notebook_table.py -i notebooks/ -o docs/notebooks.csv
    # Build pages
    - sphinx-build docs public/$DOCS_SECRET_KEY
    # Convert notebooks
    - mkdir -p public/$DOCS_SECRET_KEY/notebooks
    - ./scripts/convert_notebooks.sh notebooks/ public/$DOCS_SECRET_KEY/notebooks/
  artifacts:
    paths:
      - public
  only:
    - tags
